{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49c1148f",
   "metadata": {},
   "source": [
    "Problem 1: Data from yfinance\n",
    "Using the yfinance Python package, write a function called get_data() that downloads all hourly data for the previous five days for the five FAANG stocks:\n",
    "\n",
    "Facebook (META) / Apple (AAPL) / Amazon (AMZN) / Netflix (NFLX)/ Google (GOOG)\n",
    "\n",
    "The function should save the data into a folder called data in the root of your repository using a filename with the format YYYYMMDD-HHmmss.csv where YYYYMMDD is the four-digit year (e.g. 2025), followed by the two-digit month (e.g. 09 for September), followed by the two digit day, and HHmmss is hour, minutes, seconds. Create the data folder if you don't already have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ae3a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# https://pypi.org/project/yfinance/\n",
    "\n",
    "import yfinance as yf  # import the yfinance library to be able to fetch data for the five FAANG stocks.\n",
    "import os  # import the os library to handle file system operations.\n",
    "from datetime import datetime # import datetime to generate timestamps for the filenames.\n",
    "\n",
    "\n",
    "def get_data():    #  Creation of the function get_data():\n",
    "\n",
    "    stocks_list = ['META', 'AAPL', 'AMZN', 'NFLX', 'GOOGL'] # Creation of the List of FAANG stock tickers\n",
    "    \n",
    "    if not os.path.exists('data'):  # Creates the 'data' folder if it does not exist\n",
    "           os.makedirs('data')\n",
    "\n",
    "    for stock in stocks_list: # Loop needed to generate individual files for each stock\n",
    "         df = yf.download (tickers = stock, period ='5d', interval= '1h' , auto_adjust=False)  # Download hourly data for the last 5 days \n",
    "         timestamp = datetime.now().strftime (\"%Y%m%d_%H%M%S\")  # Get the current timestamp\n",
    "         df.to_csv(f\"data/{stock}_{timestamp}.csv\")  # Save the data to a CSV file with the stock ticker and timestamp in the filename\n",
    "         \n",
    "    return \"Download complete.\"\n",
    "\n",
    "results = get_data()   # Call the function to get the stock data\n",
    "print(results)  # Print the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed543be",
   "metadata": {},
   "source": [
    "Problem 2: Plotting Data\n",
    "Write a function called plot_data() that opens the latest data file in the data folder and, on one plot, plots the Close prices for each of the five stocks. The plot should include axis labels, a legend, and the date as a title. The function should save the plot into a plots folder in the root of your repository using a filename in the format YYYYMMDD-HHmmss.png. Create the plots folder if you don't already have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bd68552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitignore',\n",
       " '20251004-003628.csv',\n",
       " '20251004-003714.csv',\n",
       " 'AAPL_20251107_153403.csv',\n",
       " 'AAPL_20251107_155429.csv',\n",
       " 'AAPL_20251107_160711.csv',\n",
       " 'AAPL_20251107_160955.csv',\n",
       " 'AAPL_20251107_161908.csv',\n",
       " 'AAPL_20251107_163824.csv',\n",
       " 'AMZN_20251107_153403.csv',\n",
       " 'AMZN_20251107_155429.csv',\n",
       " 'AMZN_20251107_160711.csv',\n",
       " 'AMZN_20251107_160955.csv',\n",
       " 'AMZN_20251107_161909.csv',\n",
       " 'AMZN_20251107_163825.csv',\n",
       " 'GOOGL_20251107_153404.csv',\n",
       " 'GOOGL_20251107_155429.csv',\n",
       " 'GOOGL_20251107_160711.csv',\n",
       " 'GOOGL_20251107_160956.csv',\n",
       " 'GOOGL_20251107_161914.csv',\n",
       " 'GOOGL_20251107_163825.csv',\n",
       " 'META_20251107_153403.csv',\n",
       " 'META_20251107_155428.csv',\n",
       " 'META_20251107_160710.csv',\n",
       " 'META_20251107_160955.csv',\n",
       " 'META_20251107_161908.csv',\n",
       " 'META_20251107_163824.csv',\n",
       " 'NFLX_20251107_153404.csv',\n",
       " 'NFLX_20251107_155429.csv',\n",
       " 'NFLX_20251107_160711.csv',\n",
       " 'NFLX_20251107_160955.csv',\n",
       " 'NFLX_20251107_161909.csv',\n",
       " 'NFLX_20251107_163825.csv',\n",
       " 'Plotting Data.ipynb',\n",
       " 'stock_data.csv',\n",
       " 'stock_data.csv_20251103_143613.csv']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.listdir('data')  # List the files in the 'data' directory to verify that the files have been created successfully.\n",
    "files = os.listdir('data') # Sort the list of files for better readability.\n",
    "files.sort()  # Display the sorted list of files in the 'data' directory.\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b21c484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\Julia da Cruz Silva.docx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.path.join('data', 'Julia da Cruz Silva.docx')\n",
    "\n",
    "cv = os.path.join('data', 'Julia da Cruz Silva.docx')\n",
    "\n",
    "cv   # Example filename, replace with actual timestamp\n",
    "\n",
    "print(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e2f56c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(cv)  # Check if the file exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88734aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caminho completo: c:\\Users\\Julia Cruz\\8645-computer-infrastructure\\data\\Julia da Cruz Silva.docx\n",
      "Existe? True\n",
      "Pasta Atual:  c:\\Users\\Julia Cruz\\8645-computer-infrastructure\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import os\n",
    "\n",
    "cv = os.path.join('data', 'Julia da Cruz Silva.docx')\n",
    "\n",
    "print (\"caminho completo:\", os.path.abspath(cv))\n",
    "print(\"Existe?\", os.path.exists(cv))\n",
    "print(\"Pasta Atual: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3da00ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia da Cruz Silva\n",
      "Main Street Craughwell, Galway\n",
      "Mobile: 0838492723 email: juliacruz97@hotmail.com\n",
      "\n",
      "PROFESSIONAL SUMMARY\n",
      "Detail-oriented and analytical professional with 10+ years of experience in cost control, project coordination, and financial management across engineering, mining, and manufacturing sectors. Currently pursuing a Higher Diploma in Computing (Data Analytics), combining technical, financial, and analytical expertise to deliver robust commercial support. Strong track record in CAPEX/OPEX budgeting, forecasting, cost tracking, contract administration, and project audits. Seeking to contribute as a CSA Project Quantity Surveyor / Cost Engineer, applying precision, commercial awareness, and commitment to quality across all project stages.\n",
      "\n",
      "CORE SKILLS\n",
      "Cost Control & Budgeting (CAPEX/OPEX)\n",
      "Interim & Final Claims Preparation\n",
      "Contract Administration (FIDIC / NEC / JCT)\n",
      "BOQ Development & Cost Estimation\n",
      "Subcontractor Management & Valuations\n",
      "Change Management / Variations\n",
      "Financial Reporting & Forecasting\n",
      "Procurement Coordination\n",
      "Advanced Excel, Power BI & ERP Systems\n",
      "\n",
      "PROFESSIONAL EXPERIENCE\n",
      "\n",
      "TE Medical (Creganna, Galway, Ireland)\n",
      "Build Inspection Operator | Mar 2022 – Present\n",
      "Conduct detailed visual inspections and quality control across multiple assembly stages using microscopes and digital imaging systems. Ensure strict compliance with GMP standards, maintaining precise documentation, traceability, and process accuracy. Support continuous improvement initiatives and collaboration with cross-functional teams in a regulated cleanroom environment.\n",
      "\n",
      "GCS Consulting (Galway, Ireland)\n",
      "Project Quantity Surveyor | Jan 2021 – Aug 2021\n",
      "Supported commercial management of engineering projects, preparing interim valuations, claims, and cost reports in compliance with contracts. Assisted in CAPEX/OPEX budgeting, forecasting, and financial planning. Monitored commitments, accruals, and project financial progress. Participated in project audits, reviewed subcontractor accounts, and maintained change documentation. Collaborated with Project Managers and finance teams to ensure contractual compliance and timely reporting.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Bentley Systems (Dublin, Ireland)\n",
      "Project Analyst | Jun 2020 – Nov 2020\n",
      "Maintained project financial data, ensuring consistency across reporting systems. Supported project managers with cost allocation, procurement, and monthly financial reporting. Processed accruals, deferrals, and revenue recognition in compliance with GAAP/IFRS. Conducted internal audits, risk assessments, and ERP/system optimization.\n",
      "\n",
      "PROGEN Consulting LTDA. (Brazil)\n",
      "Cost Control Analyst | Jul 2013 – May 2015\n",
      "Managed CAPEX/OPEX financials, supporting project managers with budget tracking, procurement, cost allocation, and reporting. Conducted internal audits, risk assessments, and process optimization. Maintained project documentation and dashboards across SAP, SharePoint, and Confluence.\n",
      "\n",
      "Yamana Gold Mining (Brazil)\n",
      "Project Coordinator – Cost & Planning | Mar 2005 – Nov 2012\n",
      "Project Coordinator – Cost & Planning | Mar 2005 – Nov 2012\n",
      "Coordinated project activities from Exploration through Feasibility (FEL 1–3) to underground mine construction and start-up, ensuring delivery on time and within budget. Consolidated and analyzed financial data, supported budget control, CAPEX/OPEX tracking, forecasting, and cost monitoring. Conducted internal audits, facilitated lessons learned, and implemented risk mitigation strategies. Supported portfolio alignment and strategic evaluations to ensure adherence to business objectives.\n",
      "\n",
      "Career Transition Period (Brazil → Ireland)\n",
      "Independent Work and Language Studies | May 2015 – May 2019\n",
      "Relocated from Brazil and completed English language studies. Gained international work experience and developed adaptability, resilience, and strong interpersonal skills.\n",
      "\n",
      "ACADEMIC BACKGROUND\n",
      "Higher Diploma in Science – Computing (Data Analytics) – In Progress\n",
      "Executive MBA in Project Management\n",
      "Bachelor’s Degree in Business Administration\n",
      "Technical Certificate in IT Data Processing\n",
      "\n",
      "ADDITIONAL INFORMATION\n",
      "Proficient in: MS Excel (Advanced), MS Project, SAP, Power BI, ERP Systems\n",
      "Strong understanding of CSA (Civil, Structural & Architectural) construction cost structures and procurement processes.\n",
      "Excellent communication, reporting, and stakeholder coordination skills.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from docx import Document\n",
    "import os\n",
    "\n",
    "# Caminho do arquivo dentro da pasta 'data'\n",
    "file_path = os.path.join(\"data\", \"Julia da Cruz Silva.docx\")\n",
    "\n",
    "# Abre o arquivo\n",
    "doc = Document(file_path)\n",
    "\n",
    "# Extrai o texto\n",
    "texto = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "\n",
    "# Exibe o conteúdo\n",
    "print(texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e616a950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-docx\n",
      "  Using cached python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx)\n",
      "  Downloading lxml-6.0.2-cp313-cp313-win_amd64.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\julia cruz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Downloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
      "Downloading lxml-6.0.2-cp313-cp313-win_amd64.whl (4.0 MB)\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/4.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 646.5 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 646.5 kB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 0.5/4.0 MB 646.5 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 0.8/4.0 MB 571.5 kB/s eta 0:00:06\n",
      "   ------- -------------------------------- 0.8/4.0 MB 571.5 kB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 1.0/4.0 MB 598.7 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.3/4.0 MB 654.8 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 1.3/4.0 MB 654.8 kB/s eta 0:00:05\n",
      "   --------------- ------------------------ 1.6/4.0 MB 644.5 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.6/4.0 MB 644.5 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.6/4.0 MB 644.5 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.6/4.0 MB 644.5 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.6/4.0 MB 644.5 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 1.8/4.0 MB 510.3 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   -------------------- ------------------- 2.1/4.0 MB 186.8 kB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 136.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 136.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 136.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 136.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 136.9 kB/s eta 0:00:13\n",
      "   ----------------------- ---------------- 2.4/4.0 MB 136.9 kB/s eta 0:00:13\n",
      "   -------------------------- ------------- 2.6/4.0 MB 142.3 kB/s eta 0:00:10\n",
      "   -------------------------- ------------- 2.6/4.0 MB 142.3 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 2.9/4.0 MB 154.2 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 3.1/4.0 MB 166.8 kB/s eta 0:00:06\n",
      "   ------------------------------- -------- 3.1/4.0 MB 166.8 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   --------------------------------- ------ 3.4/4.0 MB 178.1 kB/s eta 0:00:04\n",
      "   ---------------------------------------- 4.0/4.0 MB 192.5 kB/s  0:00:20\n",
      "Installing collected packages: lxml, python-docx\n",
      "\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   ---------------------------------------- 0/2 [lxml]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   -------------------- ------------------- 1/2 [python-docx]\n",
      "   ---------------------------------------- 2/2 [python-docx]\n",
      "\n",
      "Successfully installed lxml-6.0.2 python-docx-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b583b1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\julia cruz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\julia cruz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-docx) (6.0.2)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\julia cruz\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-docx) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-docx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
